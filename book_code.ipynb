{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:41.984811Z",
     "start_time": "2025-04-06T21:43:37.490841Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()\n",
    "\n",
    "print(shakespeare_text[:100])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:42.340772Z",
     "start_time": "2025-04-06T21:43:41.993260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\", standardize = \"lower\")\n",
    "\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "encoded = text_vec_layer([shakespeare_text])[0]"
   ],
   "id": "404210ef4ced09b3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:42.719906Z",
     "start_time": "2025-04-06T21:43:42.713403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded -= 2 # dropping tokens 0 (pad) and 1 (unknown), which won't be currently needed\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2 #distinct token count\n",
    "dataset_size = len(encoded)"
   ],
   "id": "ffa36c5e11ae2f71",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:42.727398Z",
     "start_time": "2025-04-06T21:43:42.724414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=12):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length+1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length+1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=100000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ],
   "id": "bc29e22962bb53f7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:42.826876Z",
     "start_time": "2025-04-06T21:43:42.758423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "length = 100\n",
    "train_set = to_dataset(encoded[:1000000], length=length, shuffle=True, seed=42)\n",
    "valid_set = to_dataset(encoded[1000000:1060000], length=length)\n",
    "test_set = to_dataset(encoded[1060000:], length=length)"
   ],
   "id": "779dba1f3c6877e4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:42.837958Z",
     "start_time": "2025-04-06T21:43:42.833455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_shakespeare_model.keras\", monitor=\"val_accuracy\", save_best_only=True\n",
    ")\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=10, callbacks=[model_ckpt])'''\n"
   ],
   "id": "1594eee3404d31cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = tf.keras.Sequential([\\n    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\\n    tf.keras.layers.GRU(128, return_sequences=True),\\n    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\\n])\\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\\nmodel_ckpt = tf.keras.callbacks.ModelCheckpoint(\\n    \"my_shakespeare_model.keras\", monitor=\"val_accuracy\", save_best_only=True\\n)\\nhistory = model.fit(train_set, validation_data=valid_set, epochs=10, callbacks=[model_ckpt])'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:42.943790Z",
     "start_time": "2025-04-06T21:43:42.855575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = tf.keras.models.load_model(\"my_shakespeare_model.keras\")\n",
    "\n",
    "#Wrapping the model with text vectorization and subtractring 2 from character IDs, since it cant do it on its own\n",
    "shakespeare_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda X: X-2),\n",
    "    model\n",
    "])\n"
   ],
   "id": "3d835e1889fe5d92",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:43.702176Z",
     "start_time": "2025-04-06T21:43:42.947776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_tensor = tf.convert_to_tensor([\"To be or not to b\"])\n",
    "prediction = shakespeare_model.predict(input_tensor)\n",
    "print(prediction)\n",
    "y_proba = prediction[0][-1] #the probabilities for the last letter prediction - the one that we want to predict\n",
    "print(y_proba)"
   ],
   "id": "ad22e5ccfbe898d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adam\\Desktop\\Studia\\Cybertech\\Ksiazka\\C16\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 726ms/step\n",
      "[[[1.92323610e-01 7.56669343e-02 1.09666749e-03 1.02835700e-01\n",
      "   6.05005994e-02 5.16964383e-02 3.54065686e-01 4.74306894e-03\n",
      "   4.56992947e-02 1.75471825e-04 1.02833863e-02 1.20571032e-02\n",
      "   2.19551457e-05 1.23949926e-02 2.22976683e-04 1.38633391e-02\n",
      "   4.23508231e-03 3.12037412e-02 2.26536024e-04 2.79061933e-04\n",
      "   8.44501919e-05 3.89459601e-05 3.58245947e-04 4.50368319e-03\n",
      "   2.41744288e-04 2.20014545e-06 1.16229225e-02 1.98218203e-03\n",
      "   2.94302823e-03 3.50205111e-03 6.64717285e-04 4.53029905e-04\n",
      "   8.72320561e-06 1.08449206e-06 1.16990111e-06 2.01257791e-07\n",
      "   1.02548414e-09 2.75981440e-15 1.14279593e-12]\n",
      "  [7.64866948e-01 1.89333281e-03 2.98201655e-07 5.73598482e-02\n",
      "   1.98607049e-05 1.99654187e-05 2.98144215e-07 8.71299781e-05\n",
      "   3.34221264e-03 5.25932536e-02 3.50211374e-02 5.09416917e-03\n",
      "   3.31192382e-06 4.44670878e-02 1.81744695e-02 1.08137385e-06\n",
      "   2.58129672e-04 4.45571495e-03 6.01200827e-06 1.85256031e-05\n",
      "   5.23320341e-04 1.76423237e-05 3.86463857e-04 1.23009016e-03\n",
      "   4.65428107e-04 5.94106780e-07 1.76443253e-03 1.81206851e-03\n",
      "   8.23138631e-04 4.30551387e-04 1.86932346e-04 3.55365546e-03\n",
      "   3.40529188e-10 8.83252937e-08 8.32825663e-06 1.11442280e-03\n",
      "   9.10036196e-12 1.42346470e-15 5.81830862e-14]\n",
      "  [5.07038885e-06 7.16022588e-03 1.67021930e-01 3.19438316e-02\n",
      "   7.74682388e-02 4.30874666e-03 1.94523856e-01 9.46270823e-02\n",
      "   8.67224298e-03 5.10064594e-04 2.18599762e-05 1.89140849e-02\n",
      "   2.18529627e-02 5.44704683e-03 6.73817471e-02 4.43283431e-02\n",
      "   2.30818857e-02 1.55328976e-08 5.74557185e-02 2.72239260e-02\n",
      "   1.33869639e-02 6.89149573e-02 2.54084542e-02 8.38937126e-07\n",
      "   2.29832809e-02 3.47339874e-03 2.40809925e-07 4.32124507e-04\n",
      "   3.95372757e-09 1.54185955e-07 1.60879505e-08 1.96046994e-06\n",
      "   7.15898676e-03 6.22215588e-03 5.51636639e-08 6.75506672e-05\n",
      "   7.82650744e-09 1.26637111e-15 7.61890464e-12]\n",
      "  [7.60785326e-07 7.93824434e-01 1.50784459e-07 2.35541351e-02\n",
      "   3.83244939e-02 2.07642000e-02 5.30534798e-08 4.59636240e-09\n",
      "   2.01771837e-02 1.70868198e-11 2.96830969e-08 9.24151577e-03\n",
      "   8.20128427e-12 7.20088705e-02 1.42862069e-08 2.20996439e-02\n",
      "   3.61029535e-08 1.80874667e-06 4.30129057e-11 1.66606114e-07\n",
      "   5.45477671e-13 1.22816198e-06 2.26771828e-08 4.16968362e-08\n",
      "   3.99640343e-14 1.86377094e-11 6.97845977e-08 8.68753659e-07\n",
      "   4.20857944e-08 4.53277522e-08 2.01173393e-07 2.17972654e-10\n",
      "   3.83653287e-08 2.42284637e-10 2.14995920e-11 2.15720711e-13\n",
      "   4.14529057e-16 1.10619485e-20 5.20120151e-17]\n",
      "  [6.01849914e-01 1.44292666e-02 4.45352271e-02 4.83182230e-04\n",
      "   5.23050241e-02 2.63213795e-02 2.08996776e-02 2.23127101e-02\n",
      "   1.72920257e-03 9.43560805e-03 1.61592010e-02 2.88921017e-02\n",
      "   1.91963725e-02 1.17663876e-04 1.43867382e-03 3.50215961e-03\n",
      "   8.90026335e-04 2.41306853e-02 2.08958909e-02 1.65463462e-02\n",
      "   4.93701063e-02 4.78935908e-05 2.37046697e-04 4.66055423e-03\n",
      "   1.01711530e-05 6.95684939e-05 6.89992728e-03 1.01581914e-03\n",
      "   4.33194730e-03 5.84550528e-03 1.12923721e-04 2.04686425e-04\n",
      "   1.63974313e-04 9.57664452e-04 1.93026426e-06 1.56371982e-08\n",
      "   2.22189406e-10 3.47326092e-17 9.83757021e-13]\n",
      "  [1.60145282e-06 1.09741781e-02 1.36253253e-01 1.30262841e-02\n",
      "   1.70887321e-01 2.61364449e-02 5.74908704e-02 1.51136503e-01\n",
      "   3.81121710e-02 3.32193375e-02 5.34168521e-06 2.40271837e-02\n",
      "   2.74746120e-02 2.72007333e-03 4.89411019e-02 1.83279887e-02\n",
      "   4.97355014e-02 5.63028522e-08 2.41749678e-02 1.68228280e-02\n",
      "   4.70716283e-02 4.77942862e-02 4.33670580e-02 8.88827685e-07\n",
      "   4.11729841e-03 3.08862608e-03 3.70677839e-07 1.39938004e-03\n",
      "   3.15337845e-09 9.14869105e-08 2.79171584e-08 9.02816907e-07\n",
      "   9.38775192e-04 2.72342935e-03 1.65400452e-05 1.30525477e-05\n",
      "   2.64874540e-08 7.45970465e-14 7.22644655e-13]\n",
      "  [6.77711854e-04 1.31237938e-03 4.31721322e-02 9.20506660e-04\n",
      "   8.65040626e-03 6.84429397e-05 3.23560380e-05 1.51574874e-04\n",
      "   7.99945667e-02 1.15639009e-01 1.01061276e-04 5.42702079e-02\n",
      "   6.76165568e-03 1.00322932e-01 6.98458729e-03 1.38671328e-06\n",
      "   3.27050649e-02 4.46331775e-04 1.69428776e-03 3.39124292e-01\n",
      "   3.34869270e-08 9.53411013e-02 3.55363563e-02 2.31844515e-05\n",
      "   2.28018380e-05 3.69475409e-02 4.56925954e-05 3.42940688e-02\n",
      "   3.80505917e-05 8.17520140e-06 3.17410813e-05 4.55392683e-06\n",
      "   1.06873231e-05 1.45520247e-07 4.66476660e-03 1.11556695e-07\n",
      "   4.10558740e-13 3.66948605e-13 1.73759368e-12]\n",
      "  [2.87403196e-01 5.91973634e-03 2.18351153e-04 6.03961598e-06\n",
      "   3.85524333e-01 5.13673853e-03 3.52880661e-03 2.36829510e-03\n",
      "   4.43328827e-05 2.84237750e-02 5.13109844e-03 5.64544134e-05\n",
      "   2.19103366e-01 1.63197503e-04 9.94293005e-05 2.37122294e-04\n",
      "   2.95453909e-04 1.07004987e-02 8.57607648e-03 5.56697231e-03\n",
      "   7.84717558e-04 2.79541081e-03 2.49558352e-02 6.61115118e-05\n",
      "   5.90065611e-07 8.38751475e-07 1.16520503e-03 2.77854677e-04\n",
      "   9.95734124e-04 3.75954376e-04 1.33215826e-05 5.79363405e-05\n",
      "   1.05475954e-06 6.06207459e-06 8.85292967e-12 3.73350482e-11\n",
      "   7.55228605e-17 8.04887298e-15 3.03354293e-21]\n",
      "  [4.63508968e-06 8.22389498e-03 1.02879383e-01 1.34105468e-02\n",
      "   5.42743132e-02 1.34891002e-02 4.64868434e-02 1.64213851e-01\n",
      "   3.80122033e-03 1.51764676e-01 3.93432929e-05 6.39275312e-02\n",
      "   6.44546673e-02 3.08597274e-03 5.12603372e-02 1.46246655e-03\n",
      "   4.72665280e-02 4.41758026e-08 4.71662953e-02 5.72659746e-02\n",
      "   2.45926669e-03 7.58709833e-02 1.22456262e-02 1.96734277e-06\n",
      "   5.54810867e-05 7.68596027e-03 3.21701549e-07 1.53429632e-03\n",
      "   3.91249966e-09 1.06914797e-07 2.26444907e-08 6.15108945e-07\n",
      "   3.18119326e-03 2.47215759e-03 5.36324421e-07 1.37981306e-05\n",
      "   2.93308239e-10 2.66896694e-14 1.72329422e-13]\n",
      "  [1.70452807e-07 1.93242699e-01 3.12741300e-08 6.43888116e-01\n",
      "   6.00711741e-02 1.01363197e-01 9.94847049e-09 3.80382446e-08\n",
      "   2.68577896e-05 2.23869870e-06 1.69464656e-08 1.89394832e-05\n",
      "   4.64749377e-08 8.21611669e-04 1.90438332e-08 2.18613550e-07\n",
      "   1.15259162e-07 1.07962805e-09 8.30362660e-06 1.31533648e-06\n",
      "   5.54491300e-04 6.02760295e-08 1.00278885e-09 4.84472351e-10\n",
      "   1.36181670e-08 1.16118855e-07 8.25466584e-10 8.26232878e-08\n",
      "   3.09235471e-10 5.75690662e-10 4.16394662e-11 3.18348292e-10\n",
      "   1.34025111e-08 6.79326684e-09 1.52080499e-08 8.40538590e-08\n",
      "   2.53373786e-16 1.13880637e-20 1.06036218e-14]\n",
      "  [5.48050106e-01 1.84987621e-05 1.39259443e-01 8.70837655e-04\n",
      "   3.85243562e-04 3.93859373e-04 1.61479373e-04 4.57447208e-03\n",
      "   5.03742509e-02 9.58638042e-02 3.46696787e-02 2.35631123e-05\n",
      "   6.23010192e-06 3.40959895e-03 4.37509414e-04 2.31755566e-05\n",
      "   7.29474146e-03 4.12519500e-02 5.72380814e-05 6.27504050e-05\n",
      "   9.73527349e-05 8.07618350e-03 6.50607690e-05 9.52254632e-04\n",
      "   2.02761494e-05 9.80245313e-05 2.60821804e-02 1.71122304e-03\n",
      "   1.16513474e-02 2.28692517e-02 9.53095034e-04 2.30508595e-04\n",
      "   2.26216628e-07 1.64904634e-07 1.55737996e-06 2.90035177e-06\n",
      "   7.13495747e-15 1.04092133e-15 1.40495360e-19]\n",
      "  [5.16563773e-01 1.25301689e-01 5.40263791e-05 8.71003605e-04\n",
      "   9.20540746e-03 5.65249659e-03 2.32287705e-01 1.13911105e-04\n",
      "   3.41780804e-04 2.01523944e-04 3.12758498e-02 2.55006948e-04\n",
      "   6.94714390e-06 2.37848872e-04 2.48636667e-07 9.93133057e-04\n",
      "   2.06207186e-02 2.28860844e-02 7.02130096e-03 6.61514059e-05\n",
      "   5.80349064e-04 3.13488534e-04 1.51420920e-06 2.04051589e-03\n",
      "   1.44048216e-04 1.05835420e-08 7.38961762e-03 3.37197504e-04\n",
      "   9.21791699e-03 3.43489554e-03 1.18368749e-04 2.45243870e-03\n",
      "   6.30204227e-08 1.24161998e-05 5.88973478e-07 1.24556507e-12\n",
      "   5.18769332e-17 5.31123261e-21 2.60133661e-21]\n",
      "  [2.45159612e-07 6.02928549e-03 1.54674992e-01 2.52594780e-02\n",
      "   8.69426355e-02 4.94301207e-02 9.21552926e-02 9.20895785e-02\n",
      "   2.21855883e-02 4.07534912e-02 3.88949672e-07 1.18612591e-02\n",
      "   9.71180294e-03 1.50795300e-02 9.68561545e-02 1.22596204e-01\n",
      "   3.30341831e-02 5.25244426e-09 1.69080254e-02 2.90852319e-02\n",
      "   1.31849982e-02 3.58794741e-02 2.82057431e-02 1.00913148e-07\n",
      "   5.77846589e-03 4.76143928e-03 3.89967063e-08 2.05655652e-03\n",
      "   5.76093839e-10 2.06968167e-08 1.98227368e-09 4.30246445e-07\n",
      "   1.82713906e-03 3.54686147e-03 4.90207549e-06 1.00305602e-04\n",
      "   3.13842896e-10 1.59460701e-13 1.49115238e-14]\n",
      "  [5.51596324e-10 1.07203657e-02 4.27709028e-06 9.65932235e-02\n",
      "   1.05345435e-02 1.53088244e-02 8.37117076e-01 2.49714454e-08\n",
      "   1.77465808e-02 2.85851996e-07 1.43015044e-10 1.80823990e-04\n",
      "   6.29042987e-08 1.63525238e-03 1.81707762e-07 2.12197588e-03\n",
      "   7.99260754e-03 5.48294299e-10 4.90717957e-06 1.03215634e-05\n",
      "   7.89542753e-07 9.39370068e-07 9.22755225e-06 8.83486728e-10\n",
      "   1.09471048e-05 4.07044105e-08 1.30710653e-09 2.82860313e-09\n",
      "   4.82784812e-10 4.28043573e-10 1.74796306e-11 2.85510754e-10\n",
      "   5.13107852e-06 1.55388875e-06 1.91664662e-09 2.08266098e-08\n",
      "   1.06822435e-16 1.66214396e-19 7.55466690e-19]\n",
      "  [6.85673714e-01 3.51779955e-03 2.97135321e-05 9.22011584e-02\n",
      "   5.70986979e-03 4.14788118e-03 6.22040388e-05 4.78775054e-03\n",
      "   4.87591745e-03 2.11995766e-02 1.87736209e-02 1.53094865e-02\n",
      "   4.98513837e-05 3.26617621e-02 2.26190756e-03 1.39348413e-04\n",
      "   1.76801290e-02 3.80494283e-03 1.11066092e-05 1.38429805e-05\n",
      "   3.29867774e-03 2.60805682e-04 5.32388501e-03 1.69942563e-03\n",
      "   2.16736062e-03 9.57350608e-07 2.04658764e-03 2.03148611e-02\n",
      "   5.00898343e-04 7.82514748e-04 4.17535484e-04 5.01501001e-02\n",
      "   3.78728089e-07 7.47162261e-08 2.47554435e-05 9.95155715e-05\n",
      "   1.67637456e-13 6.00633975e-17 7.95614665e-22]\n",
      "  [9.54358075e-06 1.74426977e-02 1.64612338e-01 2.20829975e-02\n",
      "   6.45176098e-02 8.04406404e-03 1.22492656e-01 9.50203612e-02\n",
      "   1.26600312e-02 1.69861189e-03 5.01313189e-05 2.77414769e-02\n",
      "   3.47840711e-02 1.75670423e-02 6.52759746e-02 3.39286514e-02\n",
      "   1.77829377e-02 5.51211308e-08 5.67819960e-02 2.88964063e-02\n",
      "   2.09206175e-02 1.13101676e-01 3.85817997e-02 2.71673662e-06\n",
      "   1.35695310e-02 7.81912822e-03 1.12171460e-06 1.00012531e-03\n",
      "   2.09653610e-08 1.04161575e-06 4.77526108e-08 1.17370564e-05\n",
      "   6.67265337e-03 6.85218722e-03 2.00474979e-08 7.59044415e-05\n",
      "   2.17256417e-08 2.22099556e-15 1.18933793e-10]\n",
      "  [7.18308740e-07 8.04960430e-01 1.15825706e-07 1.64755769e-02\n",
      "   3.31846289e-02 2.30343118e-02 7.06118755e-08 8.28825542e-09\n",
      "   3.98197286e-02 1.61002028e-11 4.46108608e-08 9.31747630e-03\n",
      "   1.28290772e-11 4.90194783e-02 2.13470770e-08 2.41807867e-02\n",
      "   6.30484678e-08 2.10845428e-06 8.84996174e-11 2.21028671e-07\n",
      "   1.14330908e-12 2.75307821e-06 3.13399866e-08 4.94306072e-08\n",
      "   4.30840090e-14 2.98283308e-11 1.02019499e-07 8.17490729e-07\n",
      "   6.37691571e-08 5.90364699e-08 2.30785147e-07 3.37065903e-10\n",
      "   7.34413987e-08 4.73319828e-10 1.20140026e-11 2.32175471e-13\n",
      "   1.29506742e-15 1.42351160e-20 8.02375650e-17]]]\n",
      "[7.18308740e-07 8.04960430e-01 1.15825706e-07 1.64755769e-02\n",
      " 3.31846289e-02 2.30343118e-02 7.06118755e-08 8.28825542e-09\n",
      " 3.98197286e-02 1.61002028e-11 4.46108608e-08 9.31747630e-03\n",
      " 1.28290772e-11 4.90194783e-02 2.13470770e-08 2.41807867e-02\n",
      " 6.30484678e-08 2.10845428e-06 8.84996174e-11 2.21028671e-07\n",
      " 1.14330908e-12 2.75307821e-06 3.13399866e-08 4.94306072e-08\n",
      " 4.30840090e-14 2.98283308e-11 1.02019499e-07 8.17490729e-07\n",
      " 6.37691571e-08 5.90364699e-08 2.30785147e-07 3.37065903e-10\n",
      " 7.34413987e-08 4.73319828e-10 1.20140026e-11 2.32175471e-13\n",
      " 1.29506742e-15 1.42351160e-20 8.02375650e-17]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:43.718496Z",
     "start_time": "2025-04-06T21:43:43.709314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = tf.argmax(y_proba)\n",
    "print(text_vec_layer.get_vocabulary()[y_pred+2]) #adding 2, because since we subtracted it earlier, the get_vocabulary() method would return the wrong letter (one whose code is smaller by 2)"
   ],
   "id": "71875d56c0b99373",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testing categorical",
   "id": "247fe7b165658174"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:43.733671Z",
     "start_time": "2025-04-06T21:43:43.727627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log_probas = tf.math.log([[0.5, 0.4, 0.1]])  # probas = 50%, 40%, and 10%\n",
    "print(tf.random.categorical(log_probas, num_samples=8))  # draw 8 samples"
   ],
   "id": "8690279981024441",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0 1 0 2 1 0 0 1]], shape=(1, 8), dtype=int64)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:43.745252Z",
     "start_time": "2025-04-06T21:43:43.741240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def next_char(text, temperature=1):\n",
    "    tensor_text = tf.convert_to_tensor([text])\n",
    "    y_proba = shakespeare_model.predict(tensor_text, verbose=0)[0][-1:]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0][0]\n",
    "    return text_vec_layer.get_vocabulary()[char_id + 2]\n",
    "\n",
    "def extended_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ],
   "id": "df3c64ac496fbc2a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:43:48.540861Z",
     "start_time": "2025-04-06T21:43:43.758732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(extended_text(\"To be or not to b\", temperature=0.01))\n",
    "print(extended_text(\"To be or not to b\", temperature=1))\n",
    "print(extended_text(\"To be or not to b\", temperature=10))"
   ],
   "id": "32905f8ff9026176",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be or not to be a profession.\n",
      "\n",
      "provost:\n",
      "i will not be so shall b\n",
      "To be or not to bid for them dry from\n",
      "the sense, and reason with hi\n",
      "To be or not to b ysevje-cuo\n",
      "dkzido'sie.p,iqeat;;.b ha?,;,?y? u-s.!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Stateful RNN",
   "id": "1b7b4011958b04b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#previous dataset generation wouldnt work for a stateful RNN\n",
    "def to_dataset_for_stateful_rnn(sequence, length):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length+1, shift=length, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(length+1)).batch(1)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
    "\n",
    "stateful_train_set = to_dataset_for_stateful_rnn(encoded[:1000000], length)\n",
    "stateful_valid_set = to_dataset_for_stateful_rnn(encoded[1000000:1060000], length)\n",
    "stateful_test_set = to_dataset_for_stateful_rnn(encoded[1060000:], length)"
   ],
   "id": "ac79299177ddbe83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16, batch_input_shape=[1, None]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "#For resetting the state at the end of each epoch\n",
    "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()\n",
    "\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"shakespeare_model_stateful.keras\", monitor=\"val_accuracy\", save_best_only=True\n",
    ")"
   ],
   "id": "89fc626fde85d092"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(stateful_train_set, validation_data=stateful_valid_set, epochs=10, callbacks=[ResetStatesCallback(), model_ckpt])"
   ],
   "id": "bb0ac96ad3ce78d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sentiment analysis",
   "id": "daa313354ea9aecc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "raw_train_set, raw_valid_set, raw_test_set = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "train_set = raw_train_set.shuffle(5000, seed=42).batch(32).prefetch(1)\n",
    "valid_set = raw_valid_set.batch(32).prefetch(1)\n",
    "test_set = raw_test_set.batch(32).prefetch(1)"
   ],
   "id": "149f8282d62e07a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Inspecting a couple of reviews\n",
    "for review, label in raw_train_set.take(4):\n",
    "    print(review.numpy().decode(\"utf-8\"))\n",
    "    print(\"Label:\", label.numpy())"
   ],
   "id": "a400240e7bfb2709"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vocab_size = 1000\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
    "text_vec_layer.adapt(train_set.map(lambda reviews, labels: reviews))"
   ],
   "id": "4c0a6f35b99c2b94"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
